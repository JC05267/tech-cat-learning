# 06/21/2024 
# Data Engineering Bootcamp - Day #4

## AWS Athena
- interactive query service
- allows you to use SQL on unstructred data
- similar to HIVE, presto
- CTAS: `CREATE TABLE AS SELECT`. Allows for easy table creation using sql.
- ACID:
    - Athena supports ACID powered by Apache Iceberg

## ACID
- Atomicity
    - All parts of transaction must be completed successfully. If any part fails, the entire thing fails.
- Consistent
    - Must bring database from one valid state to another
- Isolation
    - Transactions are isolated from each other.
    - Operations of transactions cannot interfere with one another
- Durability
    - changes it makes are permanent even in the event of system failure.
    - once change is made, it will not be lost.
- can concurrently and reliably add and delete records

## Amazon EMR (Elastic MapReduce)
- Easily run and scale apache spark, hive presto and other big data workloads 
- 4 flavors:
    - On EC2
    - EMR studio
    - EMR serverless
    - EMR on EKS (Elastic Kubernetes Service)

## Hadoop
- HDFS - Hadoop Distributed file system
- Apache Hive - sql like query tool for big data
    - metastore to understand where the data is
    - Hive Metastore(HMS) metadata for Hive tables and partitions in a relational database
        - Has become a building block for data lakes. 
    - HiveQL
- MapReduce
    - distributes large data tasks across multiple servers and then assembles the result
    - Analogy: 
        - Count all books in a library: count the books in each section, then add them all together
    - Mapping: splitting up data, preprocessing, and converting into key-value
    - Reduce: bring it all back together
- HDFS allows data storage across sever servers efficiently while minimizing the risk of data loss

## Spark
- Resilient Distributed Datasets
- Spark uses in-memory computation
    - doesn't need to talk to HDFS each time
- lazy evaluation; doesn't evaluation expression until its needed

## Amazon SageMaker
- provides machine learning capabilities for data scientists and developers to prepare, build, and deploy ML models etc

## Data Engineering Question:
When would you use Glue?
- data transformation
- data from s3 buckets

## Big Data Architectures
### Lambda
- use lambda when working with BOTH batch and stream data
- High fault tolerance
- Data Accuracy is critical 
- Historical Data + Real Time Data  = insights
- Historical Data = Batch later
- Real time = steam layer
- Insights = serving layer

Example:
Customer Profiles (id, name, email, order history, ...)
        +
Real time clicks on website
        =
product recommendations

Batch:
- s3
- EMR
- AWS GLUE
Stream:
- Kinesis Data Streams
- Lambda
- Kinesis Data Analytics
- Amazon MSK
Serving:
- DynamoDB
- Amazon RDS
- Amazon Elastic Earch

### Kappa
Ingest -> Store -> Process -> Analyze -> Serve all happens in a single tool(Kafka)
- Real time processing
- streaming data

MSK, Kinesis, Kafka on EMR -> Sagemaker, Bedrock
